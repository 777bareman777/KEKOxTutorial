# EyeNet

## 개요
이 자료에는 Siraj Raval의 의료영상 분류에 관한  [Youtube 영상](https://youtu.be/DCcmFXXAHf4)의 소스코드가 포함되어 있습니다. 
 
## 딥러닝을 이용하여 당뇨망박병증(Diabetic Retinopathy) 검출하기 

## 목적

당뇨망막병증은 선진국에 있는 근로 연령 인구들이 실명을 하는 주요 원인입니다. 이로 인해 9,300 만 명이 넘는 사람들이 영향을 미칠 것으로 추정됩니다.

이러한 질병을 자동화된 일련의 과정을 통해 진단하고자 하는 수요는 아주 오랫동안 있었으며, 이미지 분류, 패턴 인식, 그리고 기계학습과 같은 방법들을 이용해 큰 진전이 이루어지고 있습니다. 여기에서 풀고자 하는 것은, 안구 이미지를 받아서 실제 병리 진단에 활용가능한 만큼의 이상적인 결과를 얻을 수 있는 새로운 모델을 만드는 것입니다.

이 프로젝트를 진행하게 된 계기는 다음과 같습니다:

* 우선 대규모의 데이터셋을 분류하는 것을 비롯해서, 이미지 분류는 다년간 저의 개인적인 관심사였습니다. 
  
* 환자들이 안구를 스캔하고 이 안구 영상을 의사가 분석하여 다음 진료를 예약하기 까지는 상당한 시간이 소요됩니다. 실시간으로 이미지를 처리할 수 있는 EyeNet을 사용한다면, 환자가 검사 & 치료를 하루에 전부 진행할 수 있을 것입니다. 

<p align = "center">
<img align="center" src="images/readme/dr_scan.gif" alt="Retinopathy GIF"/>
</p>


## 목차
- [EyeNet](#eyenet)
    - [개요](#%EA%B0%9C%EC%9A%94)
    - [딥러닝을 이용하여 당뇨망박병증(Diabetic Retinopathy) 검출하기](#%EB%94%A5%EB%9F%AC%EB%8B%9D%EC%9D%84-%EC%9D%B4%EC%9A%A9%ED%95%98%EC%97%AC-%EB%8B%B9%EB%87%A8%EB%A7%9D%EB%B0%95%EB%B3%91%EC%A6%9Ddiabetic-retinopathy-%EA%B2%80%EC%B6%9C%ED%95%98%EA%B8%B0)
    - [목적](#%EB%AA%A9%EC%A0%81)
    - [목차](#%EB%AA%A9%EC%B0%A8)
    - [데이터](#%EB%8D%B0%EC%9D%B4%ED%84%B0)
    - [탐색적 데이터 분석](#%ED%83%90%EC%83%89%EC%A0%81-%EB%8D%B0%EC%9D%B4%ED%84%B0-%EB%B6%84%EC%84%9D)
    - [데이터 전처리](#%EB%8D%B0%EC%9D%B4%ED%84%B0-%EC%A0%84%EC%B2%98%EB%A6%AC)
        - [Download All Images to EC2](#download-all-images-to-ec2)
        - [Crop and Resize All Images](#crop-and-resize-all-images)
        - [이미지 회전(rotate) 및 좌우반전(mirror)](#%EC%9D%B4%EB%AF%B8%EC%A7%80-%ED%9A%8C%EC%A0%84rotate-%EB%B0%8F-%EC%A2%8C%EC%9A%B0%EB%B0%98%EC%A0%84mirror)
    - [신경망 모델 구조](#%EC%8B%A0%EA%B2%BD%EB%A7%9D-%EB%AA%A8%EB%8D%B8-%EA%B5%AC%EC%A1%B0)
    - [결과](#%EA%B2%B0%EA%B3%BC)
    - [향후 과제](#%ED%96%A5%ED%9B%84-%EA%B3%BC%EC%A0%9C)
    - [참고자료](#%EC%B0%B8%EA%B3%A0%EC%9E%90%EB%A3%8C)
    - [Tech Stack](#tech-stack)
    - [크레딧](#%ED%81%AC%EB%A0%88%EB%94%A7)

## 데이터

The data originates from a [2015 Kaggle competition](https://www.kaggle.com/c/diabetic-retinopathy-detection). However, is an atypical Kaggle dataset. In most Kaggle competitions, the data has already been cleaned, giving the data scientist very little to preprocess. With this dataset, this isn't the case.

All images are taken of different people, using different cameras, and of different sizes. Pertaining to the [preprocessing](#preprocessing) section, this data is extremely noisy, and requires multiple preprocessing steps to get all images to a useable format for training a model.

The training data is comprised of 35,126 images, which are augmented during preprocessing.


## 탐색적 데이터 분석

The very first item analyzed was the training labels. While there are
five categories to predict against, the plot below shows the severe class imbalance in the original dataset.

<p align = "center">
<img align="center" src="images/eda/DR_vs_Frequency_tableau.png" alt="EDA - Class Imbalance" height="458" width="736" />
</p>

Of the original training data, 25,810 images are classified as not having retinopathy,
while 9,316 are classified as having retinopathy.

Due to the class imbalance, steps taken during [preprocessing](#preprocessing) in order to rectify the imbalance, and when training the model.

Furthermore, the variance between images of the eyes is extremely high. The first two rows of images
show class 0 (no retinopathy); the second two rows show class 4 (proliferative retinopathy).


<p align = "center">
<img align="center" src="images/readme/No_DR_white_border_1.png" alt="No DR 1"/>
<img align="center" src="images/readme/No_DR_white_border_2.png" alt="No DR 2"/>
<br></br>
<img align="center" src="images/readme/Proliferative_DR_white_border_1.png" alt="Proliferative DR 1"/>
<img align="center" src="images/readme/Proliferative_DR_white_border_2.png" alt="Proliferative DR 2"/>
</p>



## 데이터 전처리

The preprocessing pipeline is the following:

1. Download all images to EC2 using the [download script](src/download_data.sh).
2. Crop & resize all images using the [resizing script](src/resize_images.py) and the [preprocessing script](src/preprocess_images.py).
3. Rotate & mirror all images using the [rotation script](src/rotate_images.py).
4. Convert all images to array of NumPy arrays, using the [conversion script](src/image_to_array.py).

### Download All Images to EC2
The images were downloaded using the Kaggle CLI. Running this on an EC2 instance allows you to download the images in about 30 minutes. 
All images are then placed in their respective folders, and expanded from their compressed files. 
In total, the original dataset totals 35 gigabytes.

### Crop and Resize All Images
All images were scaled down to 256 by 256. Despite taking longer to train, the
detail present in photos of this size is much greater then at 128 by 128.

Additionally, 403 images were dropped from the training set. Scikit-Image raised
multiple warnings during resizing, due to these images having no color space.
Because of this, any images that were completely black were removed from the
training data.

### 이미지 회전(rotate) 및 좌우반전(mirror)
All images were rotated and mirrored.Images without retinopathy were mirrored;
images that had retinopathy were mirrored, and rotated 90, 120, 180, and 270
degrees.

The first images show two pairs of eyes, along with the black borders. Notice in
the cropping and rotations how the majority of noise is removed.

![Unscaled Images](images/readme/sample_images_unscaled.jpg)
![Rotated Images](images/readme/17_left_horizontal_white.jpg)

After rotations and mirroring, the class imbalance is rectified, with a few thousand
more images having retinopathy. In total, there are 106,386 images being processed
by the neural network.


<p align = "center">
<img align="center" src="images/eda/DR_vs_frequency_balanced.png" alt="EDA - Corrected Class Imbalance" width="664" height="458" />
</p>

## 신경망 모델 구조 
모델은 Tensorflow를 백엔드로하는 Keras에서 구현합니다. Theano 벡엔드보다는 Tensorflow 백엔드의 성능이 더 좋습니다. 그리고 TensorBoard를 활용한 아주 훌륭한 시각화 도구도 사용할 수 있습니다. 

EyeNet은 두 가지 카테고리를 예측하기 위해서 세 개의 컨볼루션 레이어를 이용합니다. 각 레이어의 깊이는 32입니다. 그리고 (2,2) 사이즈의 맥스 풀링 레이어가 각 레이어의 마지막에 적용됩니다. 

컨볼루션 레이어의 마지막 풀링이 끝나면 데이터는 128 사이즈의 단일 dense 레이어로 들어가서 최종적인 출력을 반환합니다. 최종적인 출력은 2개의 소프트맥스 노드들로 이루어집니다.

![TensorBoard CNN](images/readme/cnn_two_classes_tensorboard.png)

## 결과
The EyeNet classifier was created to determine if a patient has retinopathy. The current model returns the following scores.


| Metric | Value |
| :-----: | :-----: |
| Accuracy (Train) | 82% |
| Accuracy (Test) | 80% |
| Precision | 88% |
| Recall | 77% |


So, why does the neural network perform this way? Besides the class imbalance,
the cropping is definitely helping in the network's performance. By not having
extra black parts in the images, the network is able to process only the eye
itself.

## 향후 과제
1. Program the neural network to retrain with new photos. This is a common practice,
and only serves to optimize the model. Checks would be put in place to validate the
images before being added to the classifier, in order to prevent low quality images
from altering the classifier too drastically.


2. Port the Keras model to CoreML, and deploy to an EyeNet iOS application. CoreML
is a framework designed by Apple for adding machine learning to iOS devices.
This allows the ability of Python developers to export their models, convert the
file to a `.mlmodel` file, and add the file to the iOS development cycle.

Furthermore, the model is able to perform classification on the local
device. There is no need for an internet connection for the application to work. Because of this, the ability to use EyeNet in remote areas is further justified, and that much easier.


## 참고자료

1. [What is Diabetic Retinopathy?](http://www.mayoclinic.org/diseases-conditions/diabetic-retinopathy/basics/definition/con-20023311)

2. [Diabetic Retinopathy Winners' Interview: 4th place, Julian & Daniel](http://blog.kaggle.com/2015/08/14/diabetic-retinopathy-winners-interview-4th-place-julian-daniel/)

3. [TensorFlow: Machine Learning For Everyone](https://youtu.be/mWl45NkFBOc)

## Tech Stack
<img align="center" src="images/tech_stack/tech_stack_banner.png" alt="tech_stack_banner"/>

## 크레딧

The credits for this code go to [gregwchase](https://github.com/gregwchase/dsi-capstone). I've merely created a wrapper to get people started. 
