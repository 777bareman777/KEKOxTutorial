{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tensorflow 공식 튜토리얼 generative models DCGAN  : \n",
    "    https://github.com/tensorflow/tensorflow/blob/r1.11/tensorflow/contrib/eager/python/examples/generative_examples/dcgan.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0TD5ZrvEMbhZ"
   },
   "source": [
    "##### Copyright 2018 The TensorFlow Authors.\n",
    "\n",
    "Licensed under the Apache License, Version 2.0 (the \"License\").\n",
    "\n",
    "# tf.keras 와 eager로 구현한 DCGAN 예제\n",
    "\n",
    "<table class=\"tfo-notebook-buttons\" align=\"left\"><td>\n",
    "<a target=\"_blank\"  href=\"https://colab.research.google.com/github/tensorflow/tensorflow/blob/master/tensorflow/contrib/eager/python/examples/generative_examples/dcgan.ipynb\">\n",
    "    <img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>  \n",
    "</td><td>\n",
    "<a target=\"_blank\"  href=\"https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/eager/python/examples/generative_examples/dcgan.ipynb\"><img width=32px src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a></td></table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ITZuApL56Mny"
   },
   "source": [
    " [tf.keras](https://www.tensorflow.org/programmers_guide/keras) 와 [eager execution](https://www.tensorflow.org/programmers_guide/eager)을 사용하여 손글씨 숫자 이미지를 생성하는 예제를 설명하려 합니다.\n",
    "\n",
    "많은 방법이 있지만 이 글에서는 Deep Convolutional Generative Adverserial Networks([DCGAN](https://arxiv.org/pdf/1511.06434.pdf))를 사용하도록 하겠습니다.\n",
    "\n",
    "이 DCGAN 모델은 Colab(Tesla K80 1개)에서 학습할 때 에폭당 30초 정도 시간이 걸립니다.\n",
    "\n",
    " (using tf.contrib.eager.defun to create graph functions)\n",
    "\n",
    "아래 그림은 150 에폭 동안 모델을 학습한 후 결과입니다.\n",
    "\n",
    "![sample output](https://tensorflow.org/images/gan/dcgan.gif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "u_2z-B3piVsw"
   },
   "outputs": [],
   "source": [
    "#  gifs 형태로 생성하기 위해 imageio를 설치합니다.\n",
    "!pip install imageio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "e1_Y75QXJS6h"
   },
   "source": [
    "## Import TensorFlow and enable eager execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "YfIk2es3hJEd"
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function\n",
    "\n",
    "# TensorFlow 버전1.10 이상을 Import하고 and eager execution enable선언합니다.\n",
    "import tensorflow as tf\n",
    "tf.enable_eager_execution()\n",
    "\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import PIL\n",
    "import imageio\n",
    "from IPython import display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iYn4MdZnKCey"
   },
   "source": [
    "## 데이터셋을 불러옵니다.\n",
    "\n",
    "우리는 MNIST 데이터 셋을 사용합니다. MNIST는 손글씨 숫자 데이터셋입니다.\n",
    "생성 모델 DCGAN은 손글씨 숫자를 생성할 것 입니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "a4fYMGxGhrna"
   },
   "outputs": [],
   "source": [
    "(train_images, train_labels), (_, _) = tf.keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "NFC2ghIdiZYE"
   },
   "outputs": [],
   "source": [
    "train_images = train_images.reshape(train_images.shape[0], 28, 28, 1).astype('float32')\n",
    "#  [-1, 1] 범위로 이미지를 정규화(normalizing)합니다.\n",
    "train_images = (train_images - 127.5) / 127.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "S4PIDhoDLbsZ"
   },
   "outputs": [],
   "source": [
    "BUFFER_SIZE = 60000\n",
    "BATCH_SIZE = 256"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PIGN6ouoQxt3"
   },
   "source": [
    "## tf.data를 사용하여 데이터셋을 섞어주고(shuffle) 미니배치로 만들어줍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "-yKCCQOoJ7cn"
   },
   "outputs": [],
   "source": [
    "train_dataset = tf.data.Dataset.from_tensor_slices(train_images).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "THY-sZMiQ4UV"
   },
   "source": [
    "## generator 모델과 discriminator 모델을 만들어줍니다.\n",
    "\n",
    "* **Generator** \n",
    "  * Generator 모델은 **discriminator를 속이기 위해 그에 알맞은 이미지를 만들어내려 합니다.**.\n",
    "  *  Conv2DTranspose (Upsampling) layer로 구성되어 있습니다. fully connected layer로 시작해서 원하는 사이즈가 될 때 까지[여기서는 (28, 28, 1)] 이미지를 2배로 늘려주는 unsampling 작업을 해줍니다. \n",
    "  *  **leaky relu** 활성화 함수를 사용합니다. 마지막 layer만 tanh 활성화 함수를 사용합니다. \n",
    "  \n",
    "* **Discriminator**\n",
    "  * **The discriminator 모델은 가짜 이미지와 진짜 이미지를 구별하려 합니다.**\n",
    "  * 다시 말해, discriminator가 하는일은 \"generator가 생성한 이미지\"와 \"실제 MNIST 이미지\"를 분류하는 일입니다.\n",
    "  * **generator는 discriminator를 속일 만큼 충분한 성능이 되도록(discriminator가 생성된 이미지를 진짜라고 여기도록) 설계되어야 합니다. **."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "VGLbvBEmjK0a"
   },
   "outputs": [],
   "source": [
    "class Generator(tf.keras.Model):\n",
    "  def __init__(self):\n",
    "    super(Generator, self).__init__()\n",
    "    self.fc1 = tf.keras.layers.Dense(7*7*64, use_bias=False)\n",
    "    self.batchnorm1 = tf.keras.layers.BatchNormalization()\n",
    "    \n",
    "    self.conv1 = tf.keras.layers.Conv2DTranspose(64, (5, 5), strides=(1, 1), padding='same', use_bias=False)\n",
    "    self.batchnorm2 = tf.keras.layers.BatchNormalization()\n",
    "    \n",
    "    self.conv2 = tf.keras.layers.Conv2DTranspose(32, (5, 5), strides=(2, 2), padding='same', use_bias=False)\n",
    "    self.batchnorm3 = tf.keras.layers.BatchNormalization()\n",
    "    \n",
    "    self.conv3 = tf.keras.layers.Conv2DTranspose(1, (5, 5), strides=(2, 2), padding='same', use_bias=False)\n",
    "\n",
    "  def call(self, x, training=True):\n",
    "    x = self.fc1(x)\n",
    "    x = self.batchnorm1(x, training=training)\n",
    "    x = tf.nn.relu(x)\n",
    "\n",
    "    x = tf.reshape(x, shape=(-1, 7, 7, 64))\n",
    "\n",
    "    x = self.conv1(x)\n",
    "    x = self.batchnorm2(x, training=training)\n",
    "    x = tf.nn.relu(x)\n",
    "\n",
    "    x = self.conv2(x)\n",
    "    x = self.batchnorm3(x, training=training)\n",
    "    x = tf.nn.relu(x)\n",
    "\n",
    "    x = tf.nn.tanh(self.conv3(x))  \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "bkOfJxk5j5Hi"
   },
   "outputs": [],
   "source": [
    "class Discriminator(tf.keras.Model):\n",
    "  def __init__(self):\n",
    "    super(Discriminator, self).__init__()\n",
    "    self.conv1 = tf.keras.layers.Conv2D(64, (5, 5), strides=(2, 2), padding='same')\n",
    "    self.conv2 = tf.keras.layers.Conv2D(128, (5, 5), strides=(2, 2), padding='same')\n",
    "    self.dropout = tf.keras.layers.Dropout(0.3)\n",
    "    self.flatten = tf.keras.layers.Flatten()\n",
    "    self.fc1 = tf.keras.layers.Dense(1)\n",
    "\n",
    "  def call(self, x, training=True):\n",
    "    x = tf.nn.leaky_relu(self.conv1(x))\n",
    "    x = self.dropout(x, training=training)\n",
    "    x = tf.nn.leaky_relu(self.conv2(x))\n",
    "    x = self.dropout(x, training=training)\n",
    "    x = self.flatten(x)\n",
    "    x = self.fc1(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "gDkA05NE6QMs"
   },
   "outputs": [],
   "source": [
    "generator = Generator()\n",
    "discriminator = Discriminator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "k1HpMSLImuRi"
   },
   "outputs": [],
   "source": [
    "# Defun은  gives 10 secs/epoch performance boost\n",
    "generator.call = tf.contrib.eager.defun(generator.call)\n",
    "discriminator.call = tf.contrib.eager.defun(discriminator.call)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0FMYgY_mPfTi"
   },
   "source": [
    "## loss 함수와 옵티마이저를 정의합니다.\n",
    "\n",
    "* **Discriminator loss**\n",
    "  * discriminator loss 함수는  2 종류의 입력값을 받습니다. ; **실제 이미지, 생성된 이미지**\n",
    "  * real_loss 는 **실제 이미지**의 sigmoid cross entropy loss 입니다. 원하는 값(target)이 1이 되도록 합니다.\n",
    "  * generated_loss는  **생성된 이미지**의 sigmoid cross entropy loss 입니다. 원하는 값(target)이 0이 되도록 합니다.\n",
    "  * total_loss 는 위 두 loss의 합 입니다. \n",
    "  \n",
    "* **Generator loss**\n",
    "  * generated_loss는 생성된 이미지의 sigmoid cross entropy loss 입니다. 원하는 값(target)이 1이 되도록 합니다.\n",
    "  \n",
    "\n",
    "* discriminator와 the generator 옵티마이저들은 분리하여 학습합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "wkMNfBWlT-PV"
   },
   "outputs": [],
   "source": [
    "def discriminator_loss(real_output, generated_output):\n",
    "    # [1,1,...,1] 실제 이미지는 1으로 두기로 합니다.\n",
    "    # our generated examples to look like it\n",
    "    real_loss = tf.losses.sigmoid_cross_entropy(multi_class_labels=tf.ones_like(real_output), logits=real_output)\n",
    "\n",
    "    # [0,0,...,0] 생성된 이미지는 fake이기 때문에 0으로 두기로 합니다.\n",
    "    generated_loss = tf.losses.sigmoid_cross_entropy(multi_class_labels=tf.zeros_like(generated_output), logits=generated_output)\n",
    "\n",
    "    total_loss = real_loss + generated_loss\n",
    "\n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "90BIcCKcDMxz"
   },
   "outputs": [],
   "source": [
    "def generator_loss(generated_output):\n",
    "    return tf.losses.sigmoid_cross_entropy(tf.ones_like(generated_output), generated_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "iWCn_PVdEJZ7"
   },
   "outputs": [],
   "source": [
    "discriminator_optimizer = tf.train.AdamOptimizer(1e-4)\n",
    "generator_optimizer = tf.train.AdamOptimizer(1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mWtinsGDPJlV"
   },
   "source": [
    "## Checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "CA1w-7s2POEy"
   },
   "outputs": [],
   "source": [
    "checkpoint_dir = './training_checkpoints'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
    "checkpoint = tf.train.Checkpoint(generator_optimizer=generator_optimizer,\n",
    "                                 discriminator_optimizer=discriminator_optimizer,\n",
    "                                 generator=generator,\n",
    "                                 discriminator=discriminator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Rw1fkAczTQYh"
   },
   "source": [
    "## 학습하기\n",
    "\n",
    "* 주어진 데이터셋를 반복하여(iterating) 학습합니다.\n",
    "* generator는 입력값으로 일종의 **noise** 를 받습니다. generator 모델은 손글씨 숫자로 보이는 이미지를 출력할 것입니다.\n",
    "* discriminator는 **generator에서 생성된 이미지**와 **실제 MNIST 이미지**를 입력값으로 받습니다.\n",
    "* 그 다음, generator loss와 discriminator loss를 계산합니다. \n",
    "* 그리고나서, generator와 the discriminator의 변수들 (입력값들) 양쪽에 대해서 loss의 그레디언트(gradients)를 계산합니다. 이 결과들을 옵티마이저에 적용합니다.\n",
    "\n",
    "## 이미지를 생성하기\n",
    "\n",
    "* 학습 후, 이미지를 생성해봅시다! \n",
    "* 입력값인 noise 어레이를 만들어서 generator에 넣습니다.\n",
    "* generator은 noise를 손글씨 이미지로 변환해줍니다!\n",
    "* Last step is to plot the predictions and **voila!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "NS2GWywBbAWo"
   },
   "outputs": [],
   "source": [
    "EPOCHS = 150\n",
    "noise_dim = 100\n",
    "num_examples_to_generate = 16\n",
    "\n",
    "# 생성에 사용된 noise를 상수로 저장해서 나중에 불러올 수 있도록 합니다.\n",
    "# gan모델의 성능이 향상되는 과정을 더 쉽게 보여주도록 해줍니다.\n",
    "random_vector_for_generation = tf.random_normal([num_examples_to_generate,\n",
    "                                                 noise_dim])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "RmdVsmvhPxyy"
   },
   "outputs": [],
   "source": [
    "def generate_and_save_images(model, epoch, test_input):\n",
    "  # make sure the training parameter is set to False because we\n",
    "  # don't want to train the batchnorm layer when doing inference.\n",
    "  predictions = model(test_input, training=False)\n",
    "\n",
    "  fig = plt.figure(figsize=(4,4))\n",
    "  \n",
    "  for i in range(predictions.shape[0]):\n",
    "      plt.subplot(4, 4, i+1)\n",
    "      plt.imshow(predictions[i, :, :, 0] * 127.5 + 127.5, cmap='gray')\n",
    "      plt.axis('off')\n",
    "        \n",
    "  plt.savefig('image_at_epoch_{:04d}.png'.format(epoch))\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "2M7LmLtGEMQJ"
   },
   "outputs": [],
   "source": [
    "def train(dataset, epochs, noise_dim):  \n",
    "  for epoch in range(epochs):\n",
    "    start = time.time()\n",
    "    \n",
    "    for images in dataset:\n",
    "      # 균등 분포로 샘플링하여 noise를 생성하기\n",
    "      noise = tf.random_normal([BATCH_SIZE, noise_dim])\n",
    "      \n",
    "      with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "        generated_images = generator(noise, training=True)\n",
    "      \n",
    "        real_output = discriminator(images, training=True)\n",
    "        generated_output = discriminator(generated_images, training=True)\n",
    "        \n",
    "        gen_loss = generator_loss(generated_output)\n",
    "        disc_loss = discriminator_loss(real_output, generated_output)\n",
    "        \n",
    "      gradients_of_generator = gen_tape.gradient(gen_loss, generator.variables)\n",
    "      gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.variables)\n",
    "      \n",
    "      generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.variables))\n",
    "      discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.variables))\n",
    "\n",
    "      \n",
    "    if epoch % 1 == 0:\n",
    "      display.clear_output(wait=True)\n",
    "      generate_and_save_images(generator,\n",
    "                               epoch + 1,\n",
    "                               random_vector_for_generation)\n",
    "    \n",
    "    # 15 에폭마다 checkpoint를 저장\n",
    "    if (epoch + 1) % 15 == 0:\n",
    "      checkpoint.save(file_prefix = checkpoint_prefix)\n",
    "    \n",
    "    print ('Time taken for epoch {} is {} sec'.format(epoch + 1,\n",
    "                                                      time.time()-start))\n",
    "  # 마지막 에폭을 돌고난 후 생성하기 \n",
    "  display.clear_output(wait=True)\n",
    "  generate_and_save_images(generator,\n",
    "                           epochs,\n",
    "                           random_vector_for_generation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "Ly3UN0SLLY2l"
   },
   "outputs": [],
   "source": [
    "train(train_dataset, EPOCHS, noise_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rfM4YcPVPkNO"
   },
   "source": [
    "## 가장 최근 checkpoint를 저장하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "XhXsd0srPo8c"
   },
   "outputs": [],
   "source": [
    "# checkpoint_dir 안에 저장 \n",
    "checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "P4M_vIbUi7c0"
   },
   "source": [
    "## 에폭 수에 따른 이미지 보여주기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "WfO5wCdclHGL"
   },
   "outputs": [],
   "source": [
    "def display_image(epoch_no):\n",
    "  return PIL.Image.open('image_at_epoch_{:04d}.png'.format(epoch_no))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "5x3q9_Oe5q0A"
   },
   "outputs": [],
   "source": [
    "display_image(EPOCHS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NywiH3nL8guF"
   },
   "source": [
    "## 저장된 이미지를 GIF 로 생성하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xmO0Dmu2WICn"
   },
   "source": [
    "<!-- TODO(markdaoust): Remove the hack when Ipython version is updated -->\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "IGKQgENQ8lEI"
   },
   "outputs": [],
   "source": [
    "with imageio.get_writer('dcgan.gif', mode='I') as writer:\n",
    "  filenames = glob.glob('image*.png')\n",
    "  filenames = sorted(filenames)\n",
    "  last = -1\n",
    "  for i,filename in enumerate(filenames):\n",
    "    frame = 2*(i**0.5)\n",
    "    if round(frame) > round(last):\n",
    "      last = frame\n",
    "    else:\n",
    "      continue\n",
    "    image = imageio.imread(filename)\n",
    "    writer.append_data(image)\n",
    "  image = imageio.imread(filename)\n",
    "  writer.append_data(image)\n",
    "    \n",
    "# jupyter notebook에서 gif를 보여주기 위한 코드입니다. \n",
    "os.system('cp dcgan.gif dcgan.gif.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "uV0yiKpzNP1b"
   },
   "outputs": [],
   "source": [
    "display.Image(filename=\"dcgan.gif.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6EEG-wePkmJQ"
   },
   "source": [
    "생성된 이미지 애니메이션를 다운로드 하기 위한 Colab 코드(아래):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "4UJjSnIMOzOJ"
   },
   "outputs": [],
   "source": [
    "#from google.colab import files\n",
    "#files.download('dcgan.gif')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 글은 2018 컨트리뷰톤에서 Contribute to Keras 프로젝트로 진행했습니다.",
    "번역자: 김형섭 ",
    "이메일: times21c@gmail.com"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "dcgan.ipynb",
   "private_outputs": true,
   "provenance": [
    {
     "file_id": "1eb0NOTQapkYs3X0v-zL1x5_LFKgDISnp",
     "timestamp": 1527173385672
    }
   ],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
