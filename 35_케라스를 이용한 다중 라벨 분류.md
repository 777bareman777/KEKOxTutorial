## 케라스를 이용한 다중 라벨 분류(Multi-label classification with Keras)
[원문 링크](https://www.pyimagesearch.com/2018/05/07/multi-label-classification-with-keras/)
> 본 튜토리얼에서는 하나의 CNN을 사용해 옷의 종류와 색을 모두 분류하는 다중 라벨 분석을 다룹니다.

* Keras
* CNN
* Multi-label 
* Classification

----

해당 튜토리얼은 총 네 부분으로 나뉩니다. 

첫 번째 파트에서는 다중 라벨 분류를 위한 데이터 셋(그리고 빠르게 자신만의 데이터 셋을 구축하는 법)에 대해 알아봅니다. 

두 번째 파트에서는 다중 라벨 분류를 위해 사용할 케라스 신경망 아키텍처인 `소형VGGNet`에 대해 알아본 후, 
해당 신경망을 구현해 봅니다.  

세 번째 파트에서는 직접 구현한 `소형VGGNet`을 다중 라벨 데이터 셋에 대해 학습시켜 봅니다. 

마지막으로 학습된 신경망을 예시 이미지들에 대해 테스트 해보는 것으로 본 튜토리얼을 마무리하고, 
다중 라벨 분석이 필요한 경우, 그리고 이 때 주의해야 할 점 몇가지를 알아보도록 하겠습니다. 

### 다중 라벨 분류를 위한 데이터 셋

![dataset image](https://www.pyimagesearch.com/wp-content/uploads/2018/04/keras_multi_label_dataset.jpg)  

데이터 셋은 다음을 포함하여 총 6개 범주에 걸쳐 2,167개의 이미지들로 구성됩니다. 
* 검정색 청바지 (344개의 이미지)
* 파란색 드레스 (386개의 이미지)
* 파란색 청바지 (356개의 이미지)
* 파란색 셔츠 (369개의 이미지)
* 빨간색 드레스 (380개의 이미지)
* 빨간색 셔츠 (332개의 이미지)

***다중 라벨 분류의 목표는 옷의 종류와 색을 모두 예측하는 모델을 만드는 것입니다***

본 튜토리얼에서 사용하는 데이터 셋은 [*해당 튜토리얼*](https://www.pyimagesearch.com/2018/04/09/how-to-quickly-build-a-deep-learning-image-dataset/)을 참고하여 만들었으며, 이미지들을 다운로드하고 6개의 클래스 각각에 대해 관련 없는 이미지들을 수동으로 제거하는 과정에는 약 30분의 시간이 걸립니다.

자체적으로 딥러닝을 위한 이미지 데이터 셋을 구축하려고 한다면 위에 링크된 튜토리얼은 아주 좋은 시작점이 될 것입니다. 

### 다중 라벨 분류 프로젝트 구조 
[***해당 링크***](https://www.getdrip.com/forms/550399608/submissions)에서 코드와 파일들을 다운로드 할 수 있습니다. 
zip 파일을 추출하면 다음과 같은 디렉토리 구조가 표시됩니다.

    ├── classify.py
    ├── dataset
    │   ├── black_jeans [344 entries]
    │   ├── blue_dress [386 entries]
    │   ├── blue_jeans [356 entries]
    │   ├── blue_shirt [369 entries]
    │   ├── red_dress [380 entries]
    │   └── red_shirt [332 entries]
    ├── examples
    │   ├── example_01.jpg
    │   ├── example_02.jpg
    │   ├── example_03.jpg
    │   ├── example_04.jpg
    │   ├── example_05.jpg
    │   ├── example_06.jpg
    │   └── example_07.jpg
    ├── fashion.model
    ├── mlb.pickle
    ├── plot.png
    ├── pyimagesearch
    │   ├── __init__.py
    │   └── smallervggnet.py
    ├── search_bing_api.py
    └── train.py

zip 루트에는 6개의 파일들과 3개의 디렉토리들이 표시됩니다. 이 문서에서 다루는 중요한 파일들은 다음과 같습니다.

1. `search_bing_api.py` : 이 스크립트를 사용하여 딥러닝 학습 이미지 데이터 셋을 빠르게 구축할 수 있습니다. 하지만 이미지 데이터 셋이 이미 zip 아카이브에 포함되어 있으므로 이 스크립트를 실행할 필요는 없습니다. 해당 코드는 프로젝트의 완결성을 위해서 추가되었습니다. 
2. `train.py` : 데이터가 모이면, 해당 스크립트를 사용하여 모델을 학습시킵니다. 
3. `fashion.model` : `train.py`에 의해 디스크에 저장된 모델 객체입니다. 후에 `classify.py`스크립트에서 사용하게 됩니다. 
4. `mlb.pickle` : `train.py`에서 생성된 파일로 `scikit-learn`의 `MultiLabelBinarizer` 객체입니다. 해당 파일은 데이터의 범주 이름들을 저장하고 있습니다. 
5. `plot.png` : `plot.png`는 학습의 결과로 `train.py`에서 생성됩니다. 자체적으로 구축한 데이터 셋에 대해 학습을 진행하는 경우, 해당 파일을 통해 과적합 여부를 확인해 보는게 좋습니다. 
6. `classify.py` : 분류기를 테스트하기 위한 스크립트입니다. 다른 곳에(아이폰 딥러닝 앱이나 라즈베리 파이 딥러닝 프로젝트 같은) 모델을 배포하기 전에는 항상 로컬에서 테스트를 거치는 것이 좋습니다. 

프로젝트의 세 가지 디렉토리들은 다음과 같습니다.

1. `dataset` : 이 디렉토리는 이미지 데이터 셋을 저장하고 있으며, 각 범주마다 고유의 하위 디렉토리가 있습니다. 이 작업을 통해 (1) 데이터 셋의 구조를 정돈할 수 있으며 (2) 주어진 이미지 경로가 속한 범주의 이름을 쉽게 추출할 수 있습니다.   
2. `pyimagesearch` : `pyimagesearch`는 케라스 신경망을 포함하는 모듈입니다. `__init__.py` 파일은 해당 디렉토리를 모듈로 관리하기 위하여 존재합니다. 또 다른 파일인 `smallervggnet.py`는 신경망 모델을 만들기 위한 코드를 포함하고 있습니다.  
3. `examples` : 이 디렉토리에는 7개의 예제 이미지들이 있습니다. 각각의 이미지에 대해 `classify.py`를 사용하여 다중 라벨 분류를 진행하게 될 것입니다. 

### 다중 라벨 분류를 위한 케라스 신경망 아키텍처

![model architecture](https://www.pyimagesearch.com/wp-content/uploads/2018/04/cnn_keras_smallervggnet.png)

본 튜토리얼에서 사용하고 있는 CNN 아키텍처인 `소형VGGNet`은 `VGGNet`의 단순화된 버전입니다. `VGGNet`모델은 2014년 Simonyan과 Zisserman의 논문 [***Very Deep Convolutional Networks for Large Scale Image Recognition***](https://arxiv.org/pdf/1409.1556/)에서 처음 소개되었습니다. 

`소형VGGNet`의 아키텍처/코드에 대한 자세한 설명은 [***이 포스트***](https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-cnns/)에서 다루고 있습니다. 만약 자체적으로 모델을 디자인하고 싶다면 [***Deep Learning for Computer Vision with Python***](https://www.pyimagesearch.com/deep-learning-computer-vision-python-book/) 책을 참조해 보는 것도 좋습니다.

앞서 코드와 파일들을 다운로드 받았다면, `pyimagesearch`모듈의 `smallervggnet.py`파일을 살펴보도록 하겠습니다. 

```python
# import the necessary packages
from keras.models import Sequential
from keras.layers.normalization import BatchNormalization
from keras.layers.convolutional import Conv2D
from keras.layers.convolutional import MaxPooling2D
from keras.layers.core import Activation
from keras.layers.core import Flatten
from keras.layers.core import Dropout
from keras.layers.core import Dense
from keras import backend as K
```

먼저 관련 케라스 모듈을 가져온 다음, `소형VGGNet` 클래스를 정의합니다. 

```python
class SmallerVGGNet:
	@staticmethod
	def build(width, height, depth, classes, finalAct="softmax"):
		# initialize the model along with the input shape to be
		# "channels last" and the channels dimension itself
		model = Sequential()
		inputShape = (height, width, depth)
		chanDim = -1
 
		# if we are using "channels first", update the input shape
		# and channels dimension
		if K.image_data_format() == "channels_first":
			inputShape = (depth, height, width)
			chanDim = 1
```

모델의 정의부입니다. `build` 함수를 통해 CNN모델을 만들 수 있습니다. 

`build` 함수는 `width`, `height`, `depth`, `classes`의 총 네 가지 입력변수를 필요로 합니다.
`depth`는 입력 이미지의 채널 수를 지정하며 `classes`는 범주/클래스의 개수(정수)입니다(클래스 레이블 자체는 아님). 
`train.py` 스크립트에서 이러한 매개변수를 사용하여 96 x 96 x 3 입력 볼륨을 갖는 모델을 만들 것입니다.

또한 `finalAct`(기본값 `"softmax"`)라는 옵션을 추가적으로 줄 수 있으며, 이는 네트워크 아키텍처의 끝에서 사용됩니다. 
이 값을 `"softmax"`에서 `"sigmoid"`로 변경하여 다중 라벨 분류를 수행할 수 있습니다. 
해당 옵션을 통해 단순/다중 라벨 분류를 위한 모델들을 모두 만들 수 있습니다. 

모델은 디폴트 값인 `"channels_last"`를 기반으로 하고있으며, 
`"channels_first"`의 경우도 간단한 `if`문을 통해 지원합니다. 

다음은 첫 `CONV => RELU => POOL`블록을 만들어볼 차례입니다. 

```python
		# CONV => RELU => POOL
		model.add(Conv2D(32, (3, 3), padding="same",
			input_shape=inputShape))
		model.add(Activation("relu"))
		model.add(BatchNormalization(axis=chanDim))
		model.add(MaxPooling2D(pool_size=(3, 3)))
		model.add(Dropout(0.25))
```

위의 합성곱 계층은 32개의 필터와 3 x 3 크기의 커널을 가지며, 최종 값은 ReLU 활성화 함수를 거치게 됩니다. 

드롭아웃은 현재 계층과 다음 계층을 연결하는 노드들의 값을 무작위로 0으로 바꾸어주는 과정입니다(연결을 끊어주는 효과).
이러한 프로세스는 네트워크가 특정 클래스, 객체, 가장자리 또는 모서리를 예측하는데 있어 
계층 내 어떠한 단일 노드에만 의존하지 않게 하여 네트워크의 과적합을 예방하는데 도움이 됩니다. 

그 후 모델은 두개의 `(CONV => RELU) * 2 => POOL`블록을 거치게 됩니다.

```python
		# (CONV => RELU) * 2 => POOL
		model.add(Conv2D(64, (3, 3), padding="same"))
		model.add(Activation("relu"))
		model.add(BatchNormalization(axis=chanDim))
		model.add(Conv2D(64, (3, 3), padding="same"))
		model.add(Activation("relu"))
		model.add(BatchNormalization(axis=chanDim))
		model.add(MaxPooling2D(pool_size=(2, 2)))
		model.add(Dropout(0.25))
 
		# (CONV => RELU) * 2 => POOL
		model.add(Conv2D(128, (3, 3), padding="same"))
		model.add(Activation("relu"))
		model.add(BatchNormalization(axis=chanDim))
		model.add(Conv2D(128, (3, 3), padding="same"))
		model.add(Activation("relu"))
		model.add(BatchNormalization(axis=chanDim))
		model.add(MaxPooling2D(pool_size=(2, 2)))
		model.add(Dropout(0.25))
```

여기서 주목해야 할 점은 필터의 개수와 커널의 크기, 그리고 풀링의 크기에 변화를 주어 
공간의 크기는 점차 줄이지만, 깊이를 높인다는 것입니다. 

다음은 마지막 블록인 `FC => RELU`입니다. 

```python
		# first (and only) set of FC => RELU layers
		model.add(Flatten())
		model.add(Dense(1024))
		model.add(Activation("relu"))
		model.add(BatchNormalization())
		model.add(Dropout(0.5))
 
		# use a *softmax* activation for single-label classification
		# and *sigmoid* activation for multi-label classification
		model.add(Dense(classes))
		model.add(Activation(finalAct))
 
		# return the constructed network architecture
		return model
```

완전하게 연결된 계층인 `Dense`는 모델의 마지막에 배치됩니다. 

`Dense`의 결과 값은 마지막 활성화 함수인 `finalAct`를 거치게 됩니다. 
`"softmax"`를 사용하면 단일 라벨 분류를 수행하는 모델을 만들 수 있습니다. 
본 튜토리얼에서는 다중 라벨 분류를 위해 `"sigmoid"`를 사용합니다(`smallervggnet.py`와 `train.py` 참조). 

### 다중 라벨 분류를 위한 케라스 모델 구현 

이제 `소형VGGNet`을 구현했으니, `train.py`를 작성할 차례입니다. 이 스크립트는 다중 라벨 분류를 위해 케라스 모델을 학습시키는데 사용됩니다.

`train.py`는 [***이 포스트***](https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-cnns/)에 기반하여 작성되었기 때문에 비교하여 같이 읽어본다면 스크립트를 이해하는데 도움이 될 것입니다. 

이제 `train.py`파일을 만들어 아래와 같이 코드를 작성합니다.

```python
# set the matplotlib backend so figures can be saved in the background
import matplotlib
matplotlib.use("Agg")
 
# import the necessary packages
from keras.preprocessing.image import ImageDataGenerator
from keras.optimizers import Adam
from keras.preprocessing.image import img_to_array
from sklearn.preprocessing import MultiLabelBinarizer
from sklearn.model_selection import train_test_split
from pyimagesearch.smallervggnet import SmallerVGGNet
import matplotlib.pyplot as plt
from imutils import paths
import numpy as np
import argparse
import random
import pickle
import cv2
import os
```

위 코드에서는 해당 스크립트에 필요한 모듈들을 가져옵니다. `matplotlib.use("Agg")`로 렌더링을 위한 `matplotlib` 백엔드를 설정합니다.  
(본 튜토리얼은 Keras, scikit-learn, matplotlib, imutils 그리고 OpenCV가 모두 설치되어있다는 가정 하에 진행됩니다.)


