## 케라스를 이용한 다중 라벨 분류(Multi-label classification with Keras)
[원문 링크](https://www.pyimagesearch.com/2018/05/07/multi-label-classification-with-keras/)
> 본 튜토리얼에서는 하나의 CNN을 사용해 옷의 종류와 색을 모두 분류하는 다중 라벨 분석을 다룹니다.

* Keras
* CNN
* Multi-label 
* Classification

----

해당 튜토리얼은 총 네 부분으로 나뉩니다. 

첫 번째 파트에서는 다중 라벨 분류를 위한 데이터 셋(그리고 빠르게 자신만의 데이터 셋을 구축하는 법)에 대해 알아봅니다. 

두 번째 파트에서는 다중 라벨 분류를 위해 사용할 케라스 신경망 아키텍처인 `소형VGGNet`에 대해 알아본 후, 
해당 신경망을 구현해 봅니다.  

세 번째 파트에서는 직접 구현한 `소형VGGNet`을 다중 라벨 데이터 셋에 대해 학습시켜 봅니다. 

마지막으로 학습된 신경망을 예시 이미지들에 대해 테스트 해보는 것으로 본 튜토리얼을 마무리하고, 
다중 라벨 분석이 필요한 경우, 그리고 이 때 주의해야 할 점 몇가지를 알아보도록 하겠습니다. 

### 다중 라벨 분류를 위한 데이터 셋

![dataset image](https://www.pyimagesearch.com/wp-content/uploads/2018/04/keras_multi_label_dataset.jpg)  

데이터 셋은 다음을 포함하여 총 6개 범주에 걸쳐 2,167개의 이미지들로 구성됩니다. 
* 검정색 청바지 (344개의 이미지)
* 파란색 드레스 (386개의 이미지)
* 파란색 청바지 (356개의 이미지)
* 파란색 셔츠 (369개의 이미지)
* 빨간색 드레스 (380개의 이미지)
* 빨간색 셔츠 (332개의 이미지)

***다중 라벨 분류의 목표는 옷의 종류와 색을 모두 예측하는 모델을 만드는 것입니다***

본 튜토리얼에서 사용하는 데이터 셋은 [*해당 튜토리얼*](https://www.pyimagesearch.com/2018/04/09/how-to-quickly-build-a-deep-learning-image-dataset/)을 참고하여 만들었으며, 이미지들을 다운로드하고 6개의 클래스 각각에 대해 관련 없는 이미지들을 수동으로 제거하는 과정에는 약 30분의 시간이 걸립니다.

자체적으로 딥러닝을 위한 이미지 데이터 셋을 구축하려고 한다면 위에 링크된 튜토리얼은 아주 좋은 시작점이 될 것입니다. 

### 다중 라벨 분류 프로젝트 구조 
[***해당 링크***](https://www.getdrip.com/forms/550399608/submissions)에서 코드와 파일들을 다운로드 할 수 있습니다. 
zip 파일을 추출하면 다음과 같은 디렉토리 구조가 표시됩니다.

    ├── classify.py
    ├── dataset
    │   ├── black_jeans [344 entries]
    │   ├── blue_dress [386 entries]
    │   ├── blue_jeans [356 entries]
    │   ├── blue_shirt [369 entries]
    │   ├── red_dress [380 entries]
    │   └── red_shirt [332 entries]
    ├── examples
    │   ├── example_01.jpg
    │   ├── example_02.jpg
    │   ├── example_03.jpg
    │   ├── example_04.jpg
    │   ├── example_05.jpg
    │   ├── example_06.jpg
    │   └── example_07.jpg
    ├── fashion.model
    ├── mlb.pickle
    ├── plot.png
    ├── pyimagesearch
    │   ├── __init__.py
    │   └── smallervggnet.py
    ├── search_bing_api.py
    └── train.py

zip 루트에는 6개의 파일들과 3개의 디렉토리들이 표시됩니다. 이 문서에서 다루는 중요한 파일들은 다음과 같습니다.

1. `search_bing_api.py` : 이 스크립트를 사용하여 딥러닝 학습 이미지 데이터 셋을 빠르게 구축할 수 있습니다. 하지만 이미지 데이터 셋이 이미 zip 아카이브에 포함되어 있으므로 이 스크립트를 실행할 필요는 없습니다. 해당 코드는 프로젝트의 완결성을 위해서 추가되었습니다. 
2. `train.py` : 데이터가 모이면, 해당 스크립트를 사용하여 모델을 학습시킵니다. 
3. `fashion.model` : `train.py`에 의해 디스크에 저장된 모델 객체입니다. 후에 `classify.py`스크립트에서 사용하게 됩니다. 
4. `mlb.pickle` : `train.py`에서 생성된 파일로 `scikit-learn`의 `MultiLabelBinarizer` 객체입니다. 해당 파일은 데이터의 범주 이름들을 저장하고 있습니다. 
5. `plot.png` : `plot.png`는 학습의 결과로 `train.py`에서 생성됩니다. 자체적으로 구축한 데이터 셋에 대해 학습을 진행하는 경우, 해당 파일을 통해 과적합 여부를 확인해 보는게 좋습니다. 
6. `classify.py` : 분류기를 테스트하기 위한 스크립트입니다. 다른 곳에(아이폰 딥러닝 앱이나 라즈베리 파이 딥러닝 프로젝트 같은) 모델을 배포하기 전에는 항상 로컬에서 테스트를 거치는 것이 좋습니다. 

프로젝트의 세 가지 디렉토리들은 다음과 같습니다.

1. `dataset` : 이 디렉토리는 이미지 데이터 셋을 저장하고 있으며, 각 범주마다 고유의 하위 디렉토리가 있습니다. 이 작업을 통해 (1) 데이터 셋의 구조를 정돈할 수 있으며 (2) 주어진 이미지 경로가 속한 범주의 이름을 쉽게 추출할 수 있습니다.   
2. `pyimagesearch` : `pyimagesearch`는 케라스 신경망을 포함하는 모듈입니다. `__init__.py` 파일은 해당 디렉토리를 모듈로 관리하기 위하여 존재합니다. 또 다른 파일인 `smallervggnet.py`는 신경망 모델을 만들기 위한 코드를 포함하고 있습니다.  
3. `examples` : 이 디렉토리에는 7개의 예제 이미지들이 있습니다. 각각의 이미지에 대해 `classify.py`를 사용하여 다중 라벨 분류를 진행하게 될 것입니다. 

### 다중 라벨 분류를 위한 케라스 신경망 아키텍처

![model architecture](https://www.pyimagesearch.com/wp-content/uploads/2018/04/cnn_keras_smallervggnet.png)

본 튜토리얼에서 사용하고 있는 CNN 아키텍처인 `소형VGGNet`은 `VGGNet`의 단순화된 버전입니다. `VGGNet`모델은 2014년 Simonyan과 Zisserman의 논문 [***Very Deep Convolutional Networks for Large Scale Image Recognition***](https://arxiv.org/pdf/1409.1556/)에서 처음 소개되었습니다. 

`소형VGGNet`의 아키텍처/코드에 대한 자세한 설명은 [***이 포스트***](https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-cnns/)에서 다루고 있습니다. 만약 자체적으로 모델을 디자인하고 싶다면 [***Deep Learning for Computer Vision with Python***](https://www.pyimagesearch.com/deep-learning-computer-vision-python-book/) 책을 참조해 보는 것도 좋습니다.

앞서 코드와 파일들을 다운로드 받았다면, `pyimagesearch`모듈의 `smallervggnet.py`파일을 살펴보도록 하겠습니다. 

```python
# import the necessary packages
from keras.models import Sequential
from keras.layers.normalization import BatchNormalization
from keras.layers.convolutional import Conv2D
from keras.layers.convolutional import MaxPooling2D
from keras.layers.core import Activation
from keras.layers.core import Flatten
from keras.layers.core import Dropout
from keras.layers.core import Dense
from keras import backend as K
```

먼저 관련 케라스 모듈을 가져온 다음, `소형VGGNet` 클래스를 정의합니다. 

```python
class SmallerVGGNet:
	@staticmethod
	def build(width, height, depth, classes, finalAct="softmax"):
		# initialize the model along with the input shape to be
		# "channels last" and the channels dimension itself
		model = Sequential()
		inputShape = (height, width, depth)
		chanDim = -1
 
		# if we are using "channels first", update the input shape
		# and channels dimension
		if K.image_data_format() == "channels_first":
			inputShape = (depth, height, width)
			chanDim = 1
```

모델의 정의부입니다. `build` 함수를 통해 CNN모델을 만들 수 있습니다. 

`build` 함수는 `width`, `height`, `depth`, `classes`의 총 네 가지 입력변수를 필요로 합니다.
`depth`는 입력 이미지의 채널 수를 지정하며 `classes`는 범주/클래스의 개수(정수)입니다(클래스 라벨 자체는 아님). 
`train.py` 스크립트에서 이러한 매개변수를 사용하여 96 x 96 x 3 입력 볼륨을 갖는 모델을 만들 것입니다.

또한 `finalAct`(기본값 `"softmax"`)라는 옵션을 추가적으로 줄 수 있으며, 이는 네트워크 아키텍처의 끝에서 사용됩니다. 
이 값을 `"softmax"`에서 `"sigmoid"`로 변경하여 다중 라벨 분류를 수행할 수 있습니다. 
해당 옵션을 통해 단순/다중 라벨 분류를 위한 모델들을 모두 만들 수 있습니다. 

모델은 디폴트 값인 `"channels_last"`를 기반으로 하고있으며, 
`"channels_first"`의 경우도 간단한 `if`문을 통해 지원합니다. 

다음은 첫 `CONV => RELU => POOL`블록을 만들어볼 차례입니다. 

```python
		# CONV => RELU => POOL
		model.add(Conv2D(32, (3, 3), padding="same",
			input_shape=inputShape))
		model.add(Activation("relu"))
		model.add(BatchNormalization(axis=chanDim))
		model.add(MaxPooling2D(pool_size=(3, 3)))
		model.add(Dropout(0.25))
```

위의 합성곱 계층은 32개의 필터와 3 x 3 크기의 커널을 가지며, 최종 값은 ReLU 활성화 함수를 거치게 됩니다. 

드롭아웃은 현재 계층과 다음 계층을 연결하는 노드들의 값을 무작위로 0으로 바꾸어주는 과정입니다(연결을 끊어주는 효과).
이러한 프로세스는 네트워크가 특정 클래스, 객체, 가장자리 또는 모서리를 예측하는데 있어 
계층 내 어떠한 단일 노드에만 의존하지 않게 하여 네트워크의 과적합을 예방하는데 도움이 됩니다. 

그 후 모델은 두개의 `(CONV => RELU) * 2 => POOL`블록을 거치게 됩니다.

```python
		# (CONV => RELU) * 2 => POOL
		model.add(Conv2D(64, (3, 3), padding="same"))
		model.add(Activation("relu"))
		model.add(BatchNormalization(axis=chanDim))
		model.add(Conv2D(64, (3, 3), padding="same"))
		model.add(Activation("relu"))
		model.add(BatchNormalization(axis=chanDim))
		model.add(MaxPooling2D(pool_size=(2, 2)))
		model.add(Dropout(0.25))
 
		# (CONV => RELU) * 2 => POOL
		model.add(Conv2D(128, (3, 3), padding="same"))
		model.add(Activation("relu"))
		model.add(BatchNormalization(axis=chanDim))
		model.add(Conv2D(128, (3, 3), padding="same"))
		model.add(Activation("relu"))
		model.add(BatchNormalization(axis=chanDim))
		model.add(MaxPooling2D(pool_size=(2, 2)))
		model.add(Dropout(0.25))
```

여기서 주목해야 할 점은 필터의 개수와 커널의 크기, 그리고 풀링의 크기에 변화를 주어 
공간의 크기는 점차 줄이지만, 깊이를 높인다는 것입니다. 

다음은 마지막 블록인 `FC => RELU`입니다. 

```python
		# first (and only) set of FC => RELU layers
		model.add(Flatten())
		model.add(Dense(1024))
		model.add(Activation("relu"))
		model.add(BatchNormalization())
		model.add(Dropout(0.5))
 
		# use a *softmax* activation for single-label classification
		# and *sigmoid* activation for multi-label classification
		model.add(Dense(classes))
		model.add(Activation(finalAct))
 
		# return the constructed network architecture
		return model
```

완전하게 연결된 계층인 `Dense`는 모델의 마지막에 배치됩니다. 

`Dense`의 결과 값은 마지막 활성화 함수인 `finalAct`를 거치게 됩니다. 
`"softmax"`를 사용하면 단일 라벨 분류를 수행하는 모델을 만들 수 있습니다. 
본 튜토리얼에서는 다중 라벨 분류를 위해 `"sigmoid"`를 사용합니다(`smallervggnet.py`와 `train.py` 참조). 

### 다중 라벨 분류를 위한 케라스 모델 구현 

이제 `소형VGGNet`을 구현했으니, `train.py`를 작성할 차례입니다. 이 스크립트는 다중 라벨 분류를 위해 케라스 모델을 학습시키는데 사용됩니다.

`train.py`는 [***이 포스트***](https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-cnns/)에 기반하여 작성되었기 때문에 비교하여 같이 읽어본다면 스크립트를 이해하는데 도움이 될 것입니다. 

이제 `train.py`파일을 만들어 아래와 같이 코드를 작성합니다.

```python
# set the matplotlib backend so figures can be saved in the background
import matplotlib
matplotlib.use("Agg")
 
# import the necessary packages
from keras.preprocessing.image import ImageDataGenerator
from keras.optimizers import Adam
from keras.preprocessing.image import img_to_array
from sklearn.preprocessing import MultiLabelBinarizer
from sklearn.model_selection import train_test_split
from pyimagesearch.smallervggnet import SmallerVGGNet
import matplotlib.pyplot as plt
from imutils import paths
import numpy as np
import argparse
import random
import pickle
import cv2
import os
```

위 코드에서는 해당 스크립트에 필요한 모듈들을 가져옵니다. `matplotlib.use("Agg")`로 렌더링을 위한 `matplotlib` 백엔드를 설정합니다. (본 튜토리얼은 Keras, scikit-learn, matplotlib, imutils 그리고 OpenCV가 모두 설치되어있다는 가정 하에 진행됩니다.)

만약 이번 튜토리얼로 처음 딥러닝을 실습해보는 것이라면, 필요한 라이브러리 및 패키지들을 준비하기 위한 두 가지 옵션이 있습니다.

1. 사전에 구성된 환경(스타벅스 커피보다 저렴한 비용으로 오늘의 실습을 5분도 되지 않아 시작할 수 있습니다)
2. 자체적으로 환경을 구성

저는 클라우드에서 인스턴스 시작부터 파일 업로드와 학습, 데이터 다운로드, 
그리고 종료까지 채 수 분이 걸리지 않는 사전 구성된 환경을 선호합니다. 제가 추천하는 두 가지 환경은 다음과 같습니다. 

1. [Python을 활용한 AWS 딥러닝 AMI](https://www.pyimagesearch.com/2017/09/20/pre-configured-amazon-aws-deep-learning-ami-with-python/)
2. [Microsoft의 딥러닝을 위한 DSVM(Data Science Virtual Machine)](https://www.pyimagesearch.com/2017/09/20/pre-configured-amazon-aws-deep-learning-ami-with-python/)

만약 아직도 자체적으로 환경을 구성하기를 원하신다면(디버깅과 각종 문제 해결에 필요한 시간이 있으시다면),
다음의 블로그 포스팅들을 참고해 보시는 것을 추천해드립니다.

1. [Python 딥러닝을 위한 Ubuntu 환경 설정](https://www.pyimagesearch.com/2017/09/25/configuring-ubuntu-for-deep-learning-with-python/)
2. [Python 딥러닝을 위한 Ubuntu 16.04 + CUDA + GPU 환경 설정](https://www.pyimagesearch.com/2017/09/27/setting-up-ubuntu-16-04-cuda-gpu-for-deep-learning-with-python/)
3. [macOS에서 Python, Tensorflow, 그리고 Keras를 사용해서 딥러닝 해보기](https://www.pyimagesearch.com/2017/09/29/macos-for-deep-learning-with-python-tensorflow-and-keras/)

이제 (1) 환경설정이 모두 완료되고 (2) 필요한 패키지들을 모두 가져왔기 때문에, 명령줄 인수들을 파싱해볼 차례입니다. 

```python
# construct the argument parse and parse the arguments
ap = argparse.ArgumentParser()
ap.add_argument("-d", "--dataset", required=True,
	help="path to input dataset (i.e., directory of images)")
ap.add_argument("-m", "--model", required=True,
	help="path to output model")
ap.add_argument("-l", "--labelbin", required=True,
	help="path to output label binarizer")
ap.add_argument("-p", "--plot", type=str, default="plot.png",
	help="path to output accuracy/loss plot")
args = vars(ap.parse_args())
```

스크립트에 대한 명령줄 인수들은 함수에 대한 매개 변수들과 같습니다. 만약 비유가 이해가 가지 않으신다면 명령줄 인수에 대한 [블로그 포스팅](https://www.pyimagesearch.com/2018/03/12/python-argparse-command-line-arguments/)을 읽어보시는 것을 추천합니다. 

위 스크립트에는 총 네 가지의 인수들이 있습니다.

1. `--dataset` : 데이터 셋의 경로입니다.
2. `--model` : 디스크에 저장된 케라스 모델의 경로입니다.
3. `--labelbin` : 학습의 결과인 `MultiLabelBinarizer`가 저장될 경로입니다.
4. `--plot` : 학습 손실 값과 정확도 값의 그래프가 저장될 경로입니다.

만약 위의 변수들의 역할이 이해가 가지 않으신다면 [이 포스트](https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-cnns/) 읽어보시는 것이 좋습니다.

다음은 학습 과정에서 중요한 역할을 수행하는 몇 가지 중요한 변수를 초기화하겠습니다.

```python
# initialize the number of epochs to train for, initial learning rate,
# batch size, and image dimensions
EPOCHS = 75
INIT_LR = 1e-3
BS = 32
IMAGE_DIMS = (96, 96, 3)
```

위의 변수들은 다음과 같은 의미를 갖습니다.

* 네트워크는 75 `EPOCHS`동안 역전파를 통해 점진적으로 패턴을 학습합니다. 
* 초기 러닝 레이트는 `1e-3`(Adam 옵티마이저의 기본값)입니다. 
* 배치 크기는 `32`입니다. GPU를 사용하는 경우 GPU 성능에 따라 이 값을 조정해야 하지만, 이번 프로젝트에는 `32`의 배치 크기로 좋은 결과를 얻을 수 있습니다. 
* 위에서 설명한 바와 같이 이미지의 크기는 96 x 96이며 3개의 채널을 가지고 있습니다.

자세한 디테일은 [이전 포스트](https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-cnns/)를 참고하세요.

이 다음 두 개의 코드 블록은 학습 데이터 로드와 전처리를 수행합니다. 

```python
# grab the image paths and randomly shuffle them
print("[INFO] loading images...")
imagePaths = sorted(list(paths.list_images(args["dataset"])))
random.seed(42)
random.shuffle(imagePaths)
 
# initialize the data and labels
data = []
labels = []
```

여기서는 `imagePaths`(영상 경로)를 읽어와 무작위로 섞어준 다음, 데이터와 라벨 목록을 초기화합니다. 

그런 다음 `imagePaths`의 각각의 경로에 대해 이미지 데이터를 전처리하며 다중 클래스 라벨을 추출합니다. 

```python
# loop over the input images
for imagePath in imagePaths:
	# load the image, pre-process it, and store it in the data list
	image = cv2.imread(imagePath)
	image = cv2.resize(image, (IMAGE_DIMS[1], IMAGE_DIMS[0]))
	image = img_to_array(image)
	data.append(image)
 
	# extract set of class labels from the image path and update the
	# labels list
	l = label = imagePath.split(os.path.sep)[-2].split("_")
	labels.append(l)
```

먼저 `cv2.imread(imagePath)`를 통해 각 이미지를 메모리에 로드합니다. 그 다음 두 줄에서는 딥러닝 파이프라인의 중요한 단계인 전처리를 수행합니다. `data.append(image)`는 처리된 이미지를 데이터에 추가합니다. 다음 줄의 `split`은 다중 라벨 분류 작업을 위해 이미지 경로를 여러 라벨로 분할합니다. 해당 라인의 실행 결과로 2개의 원소를 갖는 리스트가 생성된 후, 라벨 리스트에 추가됩니다. 

다음은 위의 작업을 터미널에서 단계별로 수행해 본 예시로, 다중 라벨 파싱이 어떻게 진행되는지 자세히 알 수 있습니다. 

```python
$ python
>>> import os
>>> labels = []
>>> imagePath = "dataset/red_dress/long_dress_from_macys_red.png"
>>> l = label = imagePath.split(os.path.sep)[-2].split("_")
>>> l
['red', 'dress']
>>> labels.append(l)
>>>
>>> imagePath = "dataset/blue_jeans/stylish_blue_jeans_from_your_favorite_store.png"
>>> l = label = imagePath.split(os.path.sep)[-2].split("_")
>>> labels.append(l)
>>>
>>> imagePath = "dataset/red_shirt/red_shirt_from_target.png"
>>> l = label = imagePath.split(os.path.sep)[-2].split("_")
>>> labels.append(l)
>>>
>>> labels
[['red', 'dress'], ['blue', 'jeans'], ['red', 'shirt']]
```

보시다시피 `labels` 리스트는 "리스트의 리스트"입니다. `labels`의 각 원소는 2개의 원소를 갖는 리스트입니다. 각 리스트의 두 라벨은 입력 이미지 파일 경로를 기준으로 작성됩니다.

전처리 과정은 아직 끝나지 않았습니다.

```python
# scale the raw pixel intensities to the range [0, 1]
data = np.array(data, dtype="float") / 255.0
labels = np.array(labels)
print("[INFO] data matrix: {} images ({:.2f}MB)".format(
	len(imagePaths), data.nbytes / (1024 * 1000.0)))
```

`data` 리스트에는 NumPy 배열로 저장된 이미지들이 포함되어 있습니다. 코드 한 줄에서 리스트를 NumPy 배열로 변환하고, 픽셀 강도를 범위 `[0, 1]`로 조정합니다. 

또한 라벨을 NumPy 배열로 변환합니다. 

이제 라벨을 이진화해 봅시다. 아래 블록은 이번 포스트의 다중 클래스 분류 개념에 있어 매우 중요합니다. 

```python
# binarize the labels using scikit-learn's special multi-label
# binarizer implementation
print("[INFO] class labels:")
mlb = MultiLabelBinarizer()
labels = mlb.fit_transform(labels)
 
# loop over each of the possible class labels and show them
for (i, label) in enumerate(mlb.classes_):
	print("{}. {}".format(i + 1, label))
```

다중 클래스 분류를 위해 라벨을 이진화하려면, scikit-learn 라이브러리의 [MultiLabelBinarizer](http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MultiLabelBinarizer.html) 클래스를 활용해야 합니다. 다중 클래스 분류에는 표준 `LabelBinariser` 클래스를 사용할 수 없습니다. 위의 과정을 거쳐 사람이 읽을 수 있는 라벨들을 각 이미지가 어떤 클래스들에 속하는지 나타내는 벡터 값으로 인코딩합니다. 

다음은 `MultiLabelBinarizer`가 `("red", "math")`의 튜플을 6가지 범주가 있는 벡터로 변환하는 과정을 보여 주는 예입니다. 

```python
$ python
>>> from sklearn.preprocessing import MultiLabelBinarizer
>>> labels = [
...     ("blue", "jeans"),
...     ("blue", "dress"),
...     ("red", "dress"),
...     ("red", "shirt"),
...     ("blue", "shirt"),
...     ("black", "jeans")
... ]
>>> mlb = MultiLabelBinarizer()
>>> mlb.fit(labels)
MultiLabelBinarizer(classes=None, sparse_output=False)
>>> mlb.classes_
array(['black', 'blue', 'dress', 'jeans', 'red', 'shirt'], dtype=object)
>>> mlb.transform([("red", "dress")])
array([[0, 0, 1, 0, 1, 0]])
```

`One-hot` 인코딩은 범주형 라벨을 단일 정수에서 벡터로 변환합니다. 같은 개념은 위의 과정에도 적용됩니다(위의 경우 `Two-hot`이긴 합니다).

여기서 위의 Python 셸(`train.py`의 코드 블록과 혼동하지 마세요)의 최종 결과인 `array([[0, 0, 1, 0, 1, 0]])`에서 두 개의 범주형 라벨이 "hot"(배열에서 "1"로 표시)하여 각 라벨의 존재를 나타낸다는 것에 주목할 필요가 있습니다. 이 경우 "dress"와 "red"가 "hot"하며, 다른 모든 라벨의 값은 "0"입니다. 

이제 학습 및 테스트 분할을 구성하고, 데이터를 증강하기 위한 `ImageDataGenerator`를 초기화합니다.

```python
# partition the data into training and testing splits using 80% of
# the data for training and the remaining 20% for testing
(trainX, testX, trainY, testY) = train_test_split(data,
	labels, test_size=0.2, random_state=42)
 
# construct the image generator for data augmentation
aug = ImageDataGenerator(rotation_range=25, width_shift_range=0.1,
	height_shift_range=0.1, shear_range=0.2, zoom_range=0.2,
	horizontal_flip=True, fill_mode="nearest")
```

학습과 테스트를 위해 데이터를 분할하는 것은 머신러닝을 적용하는데 있어 일반적인 과정입니다. 위 코드 블록에서는 scikit-learn의 `train_test_split`을 통해 이미지의 80%를 학습 데이터에 할당하고, 20%를 테스트 데이터에 할당하였습니다. 

`ImageDataGenerator`는 데이터 분할 이후에 초기화합니다. 클래스당 1,000개 미만의 이미지로 작업하는 경우 데이터 증강은 거의 항상 "반드시" 해야하는 작업입니다. 

다음으로 모델을 만들고 Adam 옵티마이저를 초기화해 봅니다.

```python
# initialize the model using a sigmoid activation as the final layer
# in the network so we can perform multi-label classification
print("[INFO] compiling model...")
model = SmallerVGGNet.build(
	width=IMAGE_DIMS[1], height=IMAGE_DIMS[0],
	depth=IMAGE_DIMS[2], classes=len(mlb.classes_),
	finalAct="sigmoid")
 
# initialize the optimizer
opt = Adam(lr=INIT_LR, decay=INIT_LR / EPOCHS)
```

`SmallerVGGNet.build`로 `소형VGGNet`모델을 빌드합니다. 이 때 `finalAct="sigmoid"`는 이 모델로 다중 라벨 분류를 수행할 것임을 나타냅니다.

이제 모델을 컴파일하고 학습을 시작합니다(하드웨어에 따라 시간이 좀 걸릴 수 있습니다). 

```python
# compile the model using binary cross-entropy rather than
# categorical cross-entropy -- this may seem counterintuitive for
# multi-label classification, but keep in mind that the goal here
# is to treat each output label as an independent Bernoulli
# distribution
model.compile(loss="binary_crossentropy", optimizer=opt,
	metrics=["accuracy"])
 
# train the network
print("[INFO] training network...")
H = model.fit_generator(
	aug.flow(trainX, trainY, batch_size=BS),
	validation_data=(testX, testY),
	steps_per_epoch=len(trainX) // BS,
	epochs=EPOCHS, verbose=1)
```

`model.compile`로 모델을 컴파일할 때, **범주형 교차 엔트로피**대신 **이진 교차 엔트로피**를 사용합니다.

이것은 다중 라벨 분류에 있어 직관에 어긋나는 것처럼 보일 수 있지만, 이는 각각의 결과 라벨을 독립적인 베르누이 분포로 취급하기 위함입니다. 이를 통해 각각의 결과 노드들을 독립적으로 학습시킬 수 있습니다.

모델 빌드 후에는 증강된 데이터를 사용하여 학습을 시작합니다.

학습이 끝난 후에는 모델과 `MultiLabelBinarizer`를 디스크에 저장할 수 있습니다. 

```python
# save the model to disk
print("[INFO] serializing network...")
model.save(args["model"])
 
# save the multi-label binarizer to disk
print("[INFO] serializing label binarizer...")
f = open(args["labelbin"], "wb")
f.write(pickle.dumps(mlb))
f.close()
```

이제 정확도와 손실 값을 그래프로 나타내 봅니다.

```python
# plot the training loss and accuracy
plt.style.use("ggplot")
plt.figure()
N = EPOCHS
plt.plot(np.arange(0, N), H.history["loss"], label="train_loss")
plt.plot(np.arange(0, N), H.history["val_loss"], label="val_loss")
plt.plot(np.arange(0, N), H.history["acc"], label="train_acc")
plt.plot(np.arange(0, N), H.history["val_acc"], label="val_acc")
plt.title("Training Loss and Accuracy")
plt.xlabel("Epoch #")
plt.ylabel("Loss/Accuracy")
plt.legend(loc="upper left")
plt.savefig(args["plot"])
```

학습과 검증 과정의 정확도와 손실 값은 `plt.plot`으로 그릴 수 있으며, 이를 `plt.savefig`로 이미지 파일로 저장할 수 있습니다. 

저는 학습 과정을 그래프로 나타내는 것은 모델 자체 만큼이나 중요하다고 생각합니다. 저는 보통 블로그에 결과물을 올려 여러분과 공유하기 전에 몇 차례에 걸쳐 학습과 그 그래프를 그려 확인하는 과정을 거칩니다.

### 다중 라벨 분류를 위한 케라스 모델 학습

만약 직접 모델을 학습하고 싶지 않으면, [본 포스트](https://www.pyimagesearch.com/2018/05/07/multi-label-classification-with-keras/)의 "다운로드" 섹션에서 코드와 데이터 셋, 그리고 학습된 모델을 다운로드 받을 수 있습니다.

모델을 직접 학습하고 싶다면 터미널 창을 열어, 프로젝트 디렉토리로 이동한 후 다음과 같은 명령어를 실행해주세요. 

```shell
$ python train.py --dataset dataset --model fashion.model \
	--labelbin mlb.pickle
Using TensorFlow backend.
[INFO] loading images...
[INFO] data matrix: 2165 images (467.64MB)
[INFO] class labels:
1. black
2. blue
3. dress
4. jeans
5. red
6. shirt
[INFO] compiling model...
[INFO] training network...
Epoch 1/75
name: GeForce GTX TITAN X
54/54 [==============================] - 4s - loss: 0.3503 - acc: 0.8682 - val_loss: 0.9417 - val_acc: 0.6520
Epoch 2/75
54/54 [==============================] - 2s - loss: 0.1833 - acc: 0.9324 - val_loss: 0.7770 - val_acc: 0.5377
Epoch 3/75
54/54 [==============================] - 2s - loss: 0.1736 - acc: 0.9378 - val_loss: 1.1532 - val_acc: 0.6436
...
Epoch 73/75
54/54 [==============================] - 2s - loss: 0.0534 - acc: 0.9813 - val_loss: 0.0324 - val_acc: 0.9888
Epoch 74/75
54/54 [==============================] - 2s - loss: 0.0518 - acc: 0.9833 - val_loss: 0.0645 - val_acc: 0.9784
Epoch 75/75
54/54 [==============================] - 2s - loss: 0.0405 - acc: 0.9857 - val_loss: 0.0429 - val_acc: 0.9842
[INFO] serializing network...
[INFO] serializing label binarizer...
```

보시는 바와 같이, 모델을 75 `EPOCHS`동안 학습한 결과는 다음과 같습니다.

* 학습 데이터 셋에 대한 다중 라벨 분류 정확도 **98.57%**
* 테스트 데이터 셋에 대한 다중 라벨 분류 정확도 **98.42%**

학습 과정에서의 손실 값 및 정확도에 대한 그래프는 아래와 같습니다.

![plot image](https://www.pyimagesearch.com/wp-content/uploads/2018/04/plot.png)

### 새로운 이미지에 적용해보는 케라스 다중 라벨 분류

케라스를 이용한 다중 라벨 분류 모델의 학습이 완료되었으니, 이제는 이 모델을 테스트 데이터 셋 이외의 이미지들에 적용해볼 차례입니다.

이번 스크립트는 [이전 블로그 포스트](https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-cnns/)의 `classify.py`와 유사합니다. 다중 라벨 분류를 위해 바뀐 부분들을 주의해 주세요.

준비가 되셨다면 프로젝트 디렉토리에 `classify.py`라는 새 파일을 생성한 후, 아래와 같이 코드를 작성해주세요(혹은 위의 "다운로드" 섹션에서 받은 코드를 사용해주세요).

```python
# import the necessary packages
from keras.preprocessing.image import img_to_array
from keras.models import load_model
import numpy as np
import argparse
import imutils
import pickle
import cv2
import os
 
# construct the argument parse and parse the arguments
ap = argparse.ArgumentParser()
ap.add_argument("-m", "--model", required=True,
	help="path to trained model model")
ap.add_argument("-l", "--labelbin", required=True,
	help="path to label binarizer")
ap.add_argument("-i", "--image", required=True,
	help="path to input image")
args = vars(ap.parse_args())
```

라인 2-9에서 이 스크립트에 필요한 패키지를 가져옵니다. 이 스크립트에서는 Keras와 OpenCV를 사용할 예정입니다. 

라인 12-19는 스크립트에 필요한 명령줄 인수들을 파싱하는 부분입니다.

그 후, 입력 이미지를 불러오고, 아래와 같이 전처리 과정을 거칩니다. 

```python
# load the image
image = cv2.imread(args["image"])
output = imutils.resize(image, width=400)
 
# pre-process the image for classification
image = cv2.resize(image, (96, 96))
image = image.astype("float") / 255.0
image = img_to_array(image)
image = np.expand_dims(image, axis=0)
```

입력 이미지에 대한 전처리는 앞서 학습 데이터를 전처리 했던 방식과 같습니다. 

이제 모델과 `MultiLabelBinarizer`를 로드하고, 이미지를 분류합니다.

```python
# load the trained convolutional neural network and the multi-label
# binarizer
print("[INFO] loading network...")
model = load_model(args["model"])
mlb = pickle.loads(open(args["labelbin"], "rb").read())
 
# classify the input image then find the indexes of the two class
# labels with the *largest* probability
print("[INFO] classifying image...")
proba = model.predict(image)[0]
idxs = np.argsort(proba)[::-1][:2]
```

위 코드 블록의 첫 두 줄에서 `model`과 `MultiLabelBinarizer`를 디스크에서 메모리로 로드합니다.

그 후 (전처리된)입력 이미지를 분류하고, 상위 2개 클래스 라벨 인덱스를 다음과 같이 추출합니다.

* 연관된 확률을 기준으로 배열 인덱스를 내림차순 정렬
* 상위 두개 라벨 인덱스를 추출(모델의 상위 두 개 예측)

원한다면 더 많은 클래스 라벨들을 반환하도록 이 코드를 수정할 수 있습니다. 또한 확률에 대한 문턱값과 신뢰도가 N%를 초과하는 라벨만 반환하는 것을 추천합니다.

이제 결과 이미지에 덧씌워줄 클래스 라벨과 관련 신뢰 값들을 준비할 차례입니다.

```python
# loop over the indexes of the high confidence class labels
for (i, j) in enumerate(idxs):
	# build the label and draw the label on the image
	label = "{}: {:.2f}%".format(mlb.classes_[j], proba[j] * 100)
	cv2.putText(output, label, (10, (i * 30) + 25), 
		cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
 
# show the probabilities for each of the individual labels
for (label, p) in zip(mlb.classes_, proba):
	print("{}: {:.2f}%".format(label, p * 100))
 
# show the output image
cv2.imshow("Output", output)
cv2.waitKey(0)
```

첫 반복문은 출력 이미지에 상위 두 개의 다중 라벨 예측과 해당 신뢰도 값을 그려줍니다.

마찬가지로, 다음 반복문 에서는 터미널에 모든 예측값들을 출력해줍니다. 이는 디버깅을 편리하게 해줍니다.

그 후, 마지막으로 출력 이미지를 화면에 띄워줍니다.

### 케라스 다중 라벨 분류 결과

이제 명령줄 인수를 사용하여 `classify.py`를 실제로 사용해봅시다. CNN모델로 새로운 이미지를 분류하기 위해 위에서 설명한 코드를 수정할 필요는 없습니다.
아래와 같이 터미널에서 명령줄 인수를 사용하면 됩니다.

먼저 빨간색 드레스의 이미지를 분류해보겠습니다. 아래의 이미지를 처리하기 위해 런타임에 처리되는 명령줄 인수는 세 가지 입니다.

```shell
$ python classify.py --model fashion.model --labelbin mlb.pickle \
	--image examples/example_01.jpg
Using TensorFlow backend.
[INFO] loading network...
[INFO] classifying image...
black: 0.00%
blue: 3.58%
dress: 95.14%
jeans: 0.00%
red: 100.00%
shirt: 64.02%
```

![red dress image](https://www.pyimagesearch.com/wp-content/uploads/2018/04/keras_multi_label_output_01.png)

성공! 두 클래스 ("빨간색"과 "드레스")가 얼마나 높은 신뢰도로 예측되었는지 확인할 수 있습니다.

이번에는 파란색 드레스를 분류해봅시다.

```shell
$ python classify.py --model fashion.model --labelbin mlb.pickle \
	--image examples/example_02.jpg
Using TensorFlow backend.
[INFO] loading network...
[INFO] classifying image...
black: 0.03%
blue: 99.98%
dress: 98.50%
jeans: 0.23%
red: 0.00%
shirt: 0.74%
```

![blue dress image](https://www.pyimagesearch.com/wp-content/uploads/2018/04/keras_multi_label_output_02.png)

파란색 드레스도 문제없이 분류할 수 있습니다. 꽤 괜찮은 출발입니다! 이번에는 빨간색 셔츠를 분류해봅시다.

```shell
$ python classify.py --model fashion.model --labelbin mlb.pickle \
	--image examples/example_03.jpg
Using TensorFlow backend.
[INFO] loading network...
[INFO] classifying image...
black: 0.00%
blue: 0.69%
dress: 0.00%
jeans: 0.00%
red: 100.00%
shirt: 100.00%
```

![red shirt image](https://www.pyimagesearch.com/wp-content/uploads/2018/04/keras_multi_label_output_03.png)

이 정도면 훌륭한 결과입니다. 파란색 셔츠는 어떨까요?
